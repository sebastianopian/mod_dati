{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqPAgtWbjy5p"
      },
      "source": [
        "### All the lectures are here: https://github.com/franciscovillaescusa/ML_lectures\n",
        "\n",
        "#### In this exercise we are going to use convolutional neural networks to extract cosmological information from 2D mass projected fields from 1,000 N-body simulations belonging to the CAMELS IllustrisTNG LH suite.\n",
        "\n",
        "#### These maps contain the projected mass in a region of $25\\times 25 \\times 5 ~(h^{-1}{\\rm Mpc})^3$. The idea is that the convolutional neural network is going to look for unique features or summnary statistics that will use to determine the value of $\\Omega_{\\rm m}$ and $\\sigma_8$ from the maps themselves, without us computing summary statistics or any likelihood function.\n",
        "\n",
        "#### The data is located in dropbox here:\n",
        "[Data](https://www.dropbox.com/sh/vghnick9hr1gksr/AADPV4FMPsWpurnSl9kXZjp1a?dl=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_w04HEOkJYV"
      },
      "source": [
        "### Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39lnSqvbjvh0"
      },
      "source": [
        "import numpy as np\n",
        "import sys,os,time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwkfvCqpUH-x"
      },
      "source": [
        "### If GPUs are available, use them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzKBpJ9ZUMZ-"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA Available\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print('CUDA Not Available')\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310qUCeYl70B"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e863K7cwl7Ty"
      },
      "source": [
        "# load the maps\n",
        "maps = np.load('Images_M_IllustrisTNG_LH_grid=64_z=0.00.npy')\n",
        "print(maps.shape)\n",
        "\n",
        "# load the parameter values\n",
        "params = np.loadtxt('params_IllustrisTNG_maps.txt')\n",
        "print(params.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsR0usAmWxF"
      },
      "source": [
        "### Get familiar with the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZAXm77EmN3G"
      },
      "source": [
        "# select the first map\n",
        "map0 = maps[0]\n",
        "print('Map0 dimensions:',map0.shape)\n",
        "print('%.3e < map0 < %.3e'%(np.min(map0), np.max(map0)))\n",
        "print(map0)\n",
        "print(params[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j51CS2AqndQu"
      },
      "source": [
        "### Plot one map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3LQ2adgmQV7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "plt.ylabel(r'$X\\,[h^{-1}{\\rm Mpc}]$')\n",
        "plt.xlabel(r'$Y\\,[h^{-1}{\\rm Mpc}]$')\n",
        "\n",
        "plt.imshow(maps[0],cmap=plt.get_cmap('jet'),origin='lower',\n",
        "           extent=[0, 25, 0, 25], interpolation='bicubic',\n",
        "           norm = LogNorm(vmin=1e10,vmax=1e13))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYY3vasiDcQo"
      },
      "source": [
        "### Define the value of the (hyper-)parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNTApXWODbnk"
      },
      "source": [
        "f_maps         = 'Images_M_IllustrisTNG_LH_grid=64_z=0.00.npy' #file containing the maps\n",
        "f_params       = 'params_IllustrisTNG_maps.txt'                #file with the cosmological parameters\n",
        "maps_per_sim   = 15  #number of maps per simulation\n",
        "batch_size     = 32\n",
        "seed           = 2     #the data is randomly shuffled before being split into training, validation and testing. This set the random seed for that.\n",
        "lr             = 1e-4  #learning rate\n",
        "dr             = 0.5   #dropout rate\n",
        "hidden         = 4     #number of channels in the first CNN\n",
        "wd             = 2e-4  #weight decay\n",
        "epochs         = 100   #number of epochs to train the model\n",
        "min_valid_loss = 1e7\n",
        "f_model        = 'best_model_maps.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K73ddoc_EWRD"
      },
      "source": [
        "### Define the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrA_K4vEnm_X"
      },
      "source": [
        "# This routine creates a dataset loader\n",
        "# mode ---------> 'train', 'valid', 'test', 'all'. How to create the dataset\n",
        "# f_maps -------> file containing the maps\n",
        "# f_params -----> file containing the value of the cosmological parameters\n",
        "# batch_size ---> number of elements in the batch\n",
        "# seed ---------> the data is randomly shuffled before being split into training, validation and testing. This set the random seed for that.\n",
        "# maps_per_sim -> number of maps per simulation\n",
        "def create_dataset(mode, f_SFRD, f_params, batch_size, seed, maps_per_sim):\n",
        "\n",
        "    # create the class with the dataset\n",
        "    data_set = make_dataset(mode, f_maps, f_params, seed, maps_per_sim)\n",
        "\n",
        "    # create the data loader\n",
        "    return DataLoader(dataset=data_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# This class creates the dataset\n",
        "class make_dataset():\n",
        "\n",
        "    def __init__(self, mode, f_maps, f_params, seed, maps_per_sim):\n",
        "\n",
        "        # read the data\n",
        "        maps   = np.load(f_maps)       #read the maps\n",
        "        params = np.loadtxt(f_params)  #read value of the parameters\n",
        "\n",
        "        # get the number simulations and the number of pixels per map\n",
        "        sims     = maps.shape[0]//maps_per_sim\n",
        "        x_pixels = maps.shape[1]\n",
        "        y_pixels = maps.shape[2]\n",
        "\n",
        "        # normalize the maps\n",
        "        maps = np.log10(maps)\n",
        "        mean = np.mean(maps, dtype=np.float64)\n",
        "        std  = np.std(maps,  dtype=np.float64)\n",
        "        maps = (maps - mean)/std\n",
        "\n",
        "        # Normalize the value of the parameters\n",
        "        min_params = np.min(params, axis=0)\n",
        "        max_params = np.max(params, axis=0)\n",
        "        params     = (params - min_params)/(max_params - min_params)\n",
        "\n",
        "        # get the size and offset depending on the type of dataset\n",
        "        if   mode=='train':  size, offset = int(sims*0.70), int(sims*0.00)\n",
        "        elif mode=='valid':  size, offset = int(sims*0.15), int(sims*0.70)\n",
        "        elif mode=='test':   size, offset = int(sims*0.15), int(sims*0.85)\n",
        "        elif mode=='all':    size, offset = int(sims*1.00), int(sims*0.00)\n",
        "        else:                raise Exception('Wrong name!')\n",
        "\n",
        "        # randomly shuffle the data. Instead of 0 1 2 3...999 have a\n",
        "        # random permutation. E.g. 5 9 0 29...342\n",
        "        np.random.seed(seed)\n",
        "        ids = np.arange(sims)\n",
        "        np.random.shuffle(ids)\n",
        "        ids = ids[offset:offset+size] #select indexes of the mode\n",
        "\n",
        "        # get the indexes of the selected maps\n",
        "        indexes = np.zeros(size*maps_per_sim, dtype=np.int32)\n",
        "        count = 0\n",
        "        for i in ids:\n",
        "          for j in range(maps_per_sim):\n",
        "            indexes[count] = i*maps_per_sim + j\n",
        "            count += 1\n",
        "\n",
        "        # get the corresponding maps and parameter values\n",
        "        self.size   = size*maps_per_sim\n",
        "        self.input  = torch.tensor(maps[indexes],   dtype=torch.float32)\n",
        "        self.output = torch.tensor(params[indexes], dtype=torch.float32)\n",
        "\n",
        "        # in pytorch, maps should have dimensions of [batch, channels, height, width]\n",
        "        self.input.unsqueeze_(1)\n",
        "\n",
        "    # This protocol returns the size of the dataset\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    # This protocol returns\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input[idx], self.output[idx]\n",
        "\n",
        "# get the data\n",
        "train_loader = create_dataset('train', f_maps, f_params, batch_size, seed, maps_per_sim) #training data\n",
        "valid_loader = create_dataset('valid', f_maps, f_params, batch_size, seed, maps_per_sim) #validation data\n",
        "test_loader  = create_dataset('test',  f_maps, f_params, batch_size, seed, maps_per_sim) #test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get familiar with the convolution layer:"
      ],
      "metadata": {
        "id": "zJlyeeNXmLFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def size_out(s_in,pad,ker,stride):\n",
        "    return (s_in+2.*pad-ker-2)/stride +1"
      ],
      "metadata": {
        "id": "gBTcdBfST4NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "img_test=torch.tensor(maps[index], dtype=torch.float32, requires_grad=False)\n",
        "img_test.unsqueeze_(0) # add one dimension for the number of channels\n",
        "img_test.unsqueeze_(0) # add one dimension for the batch size\n",
        "\n",
        "print('image shape input:',img_test.shape)\n",
        "\n",
        "channel_in = 1\n",
        "hidden_channel = 1\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 2\n",
        "C1 = nn.Conv2d(channel_in,   hidden_channel, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                            bias=True, padding_mode='circular')\n",
        "\n",
        "\n",
        "# Specify custom weights and bias\n",
        "custom_weights = 1./3.*torch.ones_like(C1.weight)  # Example: Initialize with ones\n",
        "custom_bias = torch.zeros_like(C1.bias)  # Example: Initialize with zeros\n",
        "\n",
        "# Assign custom weights and bias to the convolutional layer\n",
        "C1.weight.data = custom_weights\n",
        "C1.bias.data = custom_bias\n",
        "\n",
        "print('weights',C1.weight.shape)\n",
        "print('bias',C1.bias)\n",
        "\n",
        "out_test=C1(img_test)\n",
        "\n",
        "print('image shape output:',out_test.shape,size_out(img_test.shape[-1],padding,kernel_size,stride))\n",
        "\n",
        "\n",
        "img_out = out_test.detach().numpy()\n",
        "\n",
        "plt.imshow(img_out[0,0,:,:],cmap=plt.get_cmap('jet'),origin='lower',\n",
        "           extent=[0, 25, 0, 25], interpolation='bicubic',\n",
        "           norm = LogNorm(vmin=1e10,vmax=1e13))\n",
        "plt.ylabel(r'$X\\,[h^{-1}{\\rm Mpc}]$')\n",
        "plt.xlabel(r'$Y\\,[h^{-1}{\\rm Mpc}]$')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "AINBduPVmQz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "img_test=torch.tensor(maps[index], dtype=torch.float32, requires_grad=False)\n",
        "img_test.unsqueeze_(0) # add one dimension for the number of channels\n",
        "img_test.unsqueeze_(0) # add one dimension for the batch size\n",
        "\n",
        "print('image shape input:',img_test.shape)\n",
        "\n",
        "channel_in = 1\n",
        "hidden_channel = 1\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 2\n",
        "C1 = nn.Conv2d(channel_in,   hidden_channel, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                            bias=True, padding_mode='circular')\n",
        "\n",
        "\n",
        "# # Specify custom weights and bias\n",
        "custom_bias = torch.zeros_like(C1.bias)  # Example: Initialize with zeros\n",
        "custom_weights = 1./9.*torch.ones_like(C1.weight)  # Example: Initialize with ones\n",
        "\n",
        "# kernel = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32)\n",
        "kernel = torch.tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=torch.float32)\n",
        "custom_weights=kernel.expand(1,1,-1,-1)\n",
        "print('kernel',custom_weights.shape)\n",
        "\n",
        "# Assign custom weights and bias to the convolutional layer\n",
        "C1.weight.data = custom_weights\n",
        "C1.bias.data = custom_bias\n",
        "\n",
        "print('weights',C1.weight.shape)\n",
        "print('bias',C1.bias)\n",
        "\n",
        "out_test=C1(img_test)\n",
        "\n",
        "print('image shape output:',out_test.shape,size_out(img_test.shape[-1],padding,kernel_size,stride))\n",
        "\n",
        "\n",
        "img_out = out_test.detach().numpy()\n",
        "\n",
        "plt.imshow(img_out[0,0,:,:],cmap=plt.get_cmap('jet'),origin='lower',\n",
        "           extent=[0, 25, 0, 25], interpolation='bicubic',\n",
        "           norm = LogNorm(vmin=1e10,vmax=1e13))\n",
        "plt.ylabel(r'$X\\,[h^{-1}{\\rm Mpc}]$')\n",
        "plt.xlabel(r'$Y\\,[h^{-1}{\\rm Mpc}]$')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "3p2m9d4rmYOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "img_test=torch.tensor(maps[index], dtype=torch.float32, requires_grad=False)\n",
        "img_test.unsqueeze_(0) # add one dimension for the number of channels\n",
        "img_test.unsqueeze_(0) # add one dimension for the batch size\n",
        "\n",
        "print('image shape input:',img_test.shape)\n",
        "\n",
        "channel_in = 1\n",
        "hidden_channel = 4\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 2\n",
        "C1 = nn.Conv2d(channel_in,   hidden_channel, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                            bias=True, padding_mode='circular')\n",
        "\n",
        "\n",
        "print('weights',C1.weight)\n",
        "print('bias',C1.bias)\n",
        "\n",
        "out_test=C1(img_test)\n",
        "\n",
        "print('image shape output:',out_test.shape,size_out(img_test.shape[-1],padding,kernel_size,stride))\n",
        "\n",
        "\n",
        "img_out = out_test.detach().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(1, hidden_channel,figsize=(12,4) , gridspec_kw={'wspace': 0.2})\n",
        "\n",
        "\n",
        "for i in range(hidden_channel):\n",
        "    ax[i].imshow(img_out[0,i,:,:],cmap=plt.get_cmap('jet'),origin='lower',\n",
        "               extent=[0, 25, 0, 25], interpolation='bicubic',\n",
        "               norm = LogNorm(vmin=1e10,vmax=1e13))\n",
        "    ax[i].set_ylabel(r'$X\\,[h^{-1}{\\rm Mpc}]$')\n",
        "    ax[i].set_xlabel(r'$Y\\,[h^{-1}{\\rm Mpc}]$')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YWmd4sn-mbWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeVDy1zYG5Rv"
      },
      "source": [
        "### Define the architecture of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXcNu1AXDUP5"
      },
      "source": [
        "class model_a(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden, dropout_rate):\n",
        "        super(model_a, self).__init__()\n",
        "\n",
        "        # define the layers here\n",
        "        # input: 1x64x64 ----------> output: hiddenx32x32\n",
        "        self.C1 = nn.Conv2d(1,   hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B1 = nn.BatchNorm2d(hidden)\n",
        "\n",
        "        # input: hiddenx32x32 --------> output: 2*hiddenx16x16\n",
        "        self.C2 = nn.Conv2d(hidden, 2*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B2 = nn.BatchNorm2d(2*hidden)\n",
        "\n",
        "        # input: 4*hiddenx16x16 ----------> output: 8*hiddenx8x8\n",
        "        self.C3 = nn.Conv2d(2*hidden, 4*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B3 = nn.BatchNorm2d(4*hidden)\n",
        "\n",
        "        # input: 8*hiddenx8x8 ----------> output: 16*hiddenx4x4\n",
        "        self.C4 = nn.Conv2d(4*hidden, 8*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B4 = nn.BatchNorm2d(8*hidden)\n",
        "\n",
        "        # input: 16*hiddenx4x4 ----------> output: 32*hidden*x2x2\n",
        "        self.C5 = nn.Conv2d(8*hidden, 16*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "\n",
        "        self.FC1  = nn.Linear(16*hidden*2*2, 2)\n",
        "\n",
        "        self.dropout   = nn.Dropout(p=0.5)\n",
        "        self.ReLU      = nn.ReLU()\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.tanh      = nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        x = self.LeakyReLU(self.B1(self.C1(image)))\n",
        "        x = self.LeakyReLU(self.B2(self.C2(x)))\n",
        "        x = self.LeakyReLU(self.B3(self.C3(x)))\n",
        "        x = self.LeakyReLU(self.B4(self.C4(x)))\n",
        "        x = self.LeakyReLU(self.C5(x))\n",
        "        x = x.view(image.shape[0],-1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.FC1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class model_b(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden, dropout_rate):\n",
        "        super(model_b, self).__init__()\n",
        "\n",
        "        # define the layers here\n",
        "        # input: 1x64x64 ----------> output: hiddenx32x32\n",
        "        self.C0 = nn.Conv2d(1,   hidden, kernel_size=3, stride=1, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.C1 = nn.Conv2d(hidden, hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B0 = nn.BatchNorm2d(hidden)\n",
        "        self.B1 = nn.BatchNorm2d(hidden)\n",
        "\n",
        "        # input: hiddenx32x32 --------> output: 2*hiddenx16x16\n",
        "        self.C2 = nn.Conv2d(hidden,   2*hidden, kernel_size=3, stride=1, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.C3 = nn.Conv2d(2*hidden, 2*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B2 = nn.BatchNorm2d(2*hidden)\n",
        "        self.B3 = nn.BatchNorm2d(2*hidden)\n",
        "\n",
        "        # input: 4*hiddenx16x16 ----------> output: 8*hiddenx8x8\n",
        "        self.C4 = nn.Conv2d(2*hidden, 4*hidden, kernel_size=3, stride=1, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.C5 = nn.Conv2d(4*hidden, 4*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B4 = nn.BatchNorm2d(4*hidden)\n",
        "        self.B5 = nn.BatchNorm2d(4*hidden)\n",
        "\n",
        "        # input: 8*hiddenx8x8 ----------> output: 16*hiddenx4x4\n",
        "        self.C6 = nn.Conv2d(4*hidden, 8*hidden, kernel_size=3, stride=1, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.C7 = nn.Conv2d(8*hidden, 8*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B6 = nn.BatchNorm2d(8*hidden)\n",
        "        self.B7 = nn.BatchNorm2d(8*hidden)\n",
        "\n",
        "        # input: 16*hiddenx4x4 ----------> output: 32*hidden*x2x2\n",
        "        self.C8 = nn.Conv2d(8*hidden, 16*hidden, kernel_size=3, stride=1, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.C9 = nn.Conv2d(16*hidden, 16*hidden, kernel_size=4, stride=2, padding=1,\n",
        "                            bias=True, padding_mode='circular')\n",
        "        self.B8 = nn.BatchNorm2d(16*hidden)\n",
        "\n",
        "        self.FC1  = nn.Linear(16*hidden*2*2, 2)\n",
        "\n",
        "        self.dropout   = nn.Dropout(p=0.5)\n",
        "        self.ReLU      = nn.ReLU()\n",
        "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
        "        self.tanh      = nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        x = self.LeakyReLU(self.B0(self.C0(image)))\n",
        "        x = self.LeakyReLU(self.B1(self.C1(x)))\n",
        "        x = self.LeakyReLU(self.B2(self.C2(x)))\n",
        "        x = self.LeakyReLU(self.B3(self.C3(x)))\n",
        "        x = self.LeakyReLU(self.B4(self.C4(x)))\n",
        "        x = self.LeakyReLU(self.B5(self.C5(x)))\n",
        "        x = self.LeakyReLU(self.B6(self.C6(x)))\n",
        "        x = self.LeakyReLU(self.B7(self.C7(x)))\n",
        "        x = self.LeakyReLU(self.B8(self.C8(x)))\n",
        "        x = self.LeakyReLU(self.C9(x))\n",
        "        x = x.view(image.shape[0],-1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.FC1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# get the model and move it to the GPU\n",
        "model = model_a(hidden, dr)  #architecture\n",
        "model.to(device=device) #move the architecture to the GPU, if available\n",
        "\n",
        "# compute the number of parameters in the model\n",
        "network_total_params = sum(p.numel() for p in model.parameters())\n",
        "print('total number of parameters in the model = %d'%network_total_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6KEF6B9UcS5"
      },
      "source": [
        "### Define the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUPSS0v1UTZ9"
      },
      "source": [
        "criterion = nn.MSELoss()  #loss function. In this case MSE (mean squared error)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=wd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtcVvJbJU3eU"
      },
      "source": [
        "### Train!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R39-GKLrUvB7"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "# do a loop over all epochs\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # do training\n",
        "    train_loss, points = 0.0, 0\n",
        "    model.train()  #set this when training. Some architecture pieces, e.g. dropout behave differently\n",
        "    for maps_train, params_train in train_loader:  #do a loop over all elements in the training set\n",
        "\n",
        "        # get the number of elements in the batch\n",
        "        bs = maps_train.shape[0]\n",
        "\n",
        "        # move data to GPU\n",
        "        maps_train   = maps_train.to(device)\n",
        "        params_train = params_train.to(device)\n",
        "\n",
        "        # compute the value predicted by the network\n",
        "        params_pred  = model(maps_train)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(params_pred, params_train)\n",
        "\n",
        "        # compute cumulative loss and number of examples used\n",
        "        train_loss += loss.item()*bs\n",
        "        points     += bs\n",
        "\n",
        "        # zero gradients and do backpropagation. This is the magic!\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # get the average training loss\n",
        "    train_loss /= points\n",
        "\n",
        "\n",
        "    # do validation\n",
        "    valid_loss, points = 0.0, 0\n",
        "    model.eval()   #set this for validation and testing. Some architecture pieces, e.g. dropout behave differently\n",
        "    for maps_val, params_val in valid_loader: # do a loop over all elements in the validation set\n",
        "        with torch.no_grad():   #put this for validation/testing, so save memory and be more efficient. It tells to dont save gradients.\n",
        "\n",
        "            # get the number of elements in the batch\n",
        "            bs = maps_val.shape[0]\n",
        "\n",
        "            # move data to the GPU\n",
        "            maps_val   = maps_val.to(device)\n",
        "            params_val = params_val.to(device)\n",
        "\n",
        "            # compute prediction by the network\n",
        "            params_pred = model(maps_val)\n",
        "\n",
        "            # compute cumulative loss and number of examples used\n",
        "            valid_loss += criterion(params_pred, params_val).item()*bs\n",
        "            points     += bs\n",
        "\n",
        "    # get the average validation loss\n",
        "    valid_loss /= points\n",
        "\n",
        "    # save model if it has a lower validation loss\n",
        "    print('%03d %.3e %.3e'%(epoch, train_loss, valid_loss), end='')\n",
        "    if valid_loss<min_valid_loss:\n",
        "        torch.save(model.state_dict(), f_model)\n",
        "        min_valid_loss = valid_loss\n",
        "        print(' (best-model)')\n",
        "    else:\n",
        "        print('')\n",
        "\n",
        "\n",
        "stop = time.time()\n",
        "print('Time taken (seconds):', \"{:.4f}\".format(stop-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0DPvSm3WRKG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_wGIRFx9UqH"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiLAmbEFiga8"
      },
      "source": [
        "# get the test data\n",
        "test_loader = create_dataset('test', f_maps, f_params, batch_size, seed, maps_per_sim) #test data\n",
        "\n",
        "# get the number of maps in the test set\n",
        "num_maps = 0\n",
        "for x,y in test_loader:\n",
        "  num_maps += x.shape[0]\n",
        "\n",
        "# define the arrays with the results\n",
        "params_T = np.zeros((num_maps,2), dtype=np.float32) #true values\n",
        "params_N = np.zeros((num_maps,2), dtype=np.float32) #network values\n",
        "\n",
        "# load the best-model and move it to the GPU\n",
        "model.load_state_dict(torch.load(f_model))\n",
        "model.to(device=device)\n",
        "\n",
        "# loop over the different batches and get the prediction\n",
        "offset = 0\n",
        "test_loss, points = 0.0, 0\n",
        "model.eval()\n",
        "for maps_test, params_test in test_loader:\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # get the number of elements in the batch\n",
        "        bs = maps_test.shape[0]\n",
        "\n",
        "        # move data to GPU\n",
        "        maps_test   = maps_test.to(device)\n",
        "        params_test = params_test.to(device)\n",
        "\n",
        "        # make prediction using network\n",
        "        params_pred = model(maps_test)\n",
        "\n",
        "        params_T[points:points+bs] = params_test.cpu().numpy()\n",
        "        params_N[points:points+bs] = params_pred.cpu().numpy()\n",
        "\n",
        "        # compute cumulative loss and number of examples used\n",
        "        test_loss += criterion(params_pred, params_test).item()*bs\n",
        "        points    += bs\n",
        "\n",
        "# get the average validation loss\n",
        "test_loss /= points\n",
        "\n",
        "print('test loss = %.3e'%test_loss)\n",
        "\n",
        "# denormalize the data\n",
        "params_T[:,0] = params_T[:,0]*(0.5-0.1) + 0.1\n",
        "params_N[:,0] = params_N[:,0]*(0.5-0.1) + 0.1\n",
        "\n",
        "params_T[:,1] = params_T[:,1]*(1.0-0.6) + 0.6\n",
        "params_N[:,1] = params_N[:,1]*(1.0-0.6) + 0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvZ5OpWjp5V"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'wspace': 0.2})\n",
        "\n",
        "for ax in [ax1,ax2]:\n",
        "  ax.set_xlabel(r'${\\rm True}$')\n",
        "ax1.set_ylabel(r'${\\rm Prediction}$')\n",
        "\n",
        "ax1.plot(params_T[:,0], params_N[:,0], ls='None', marker='*')\n",
        "ax1.plot([0.1,0.5],[0.1,0.5])\n",
        "\n",
        "ax2.plot(params_T[:,1], params_N[:,1], ls='None', marker='*')\n",
        "ax2.plot([0.6,1.0],[0.6,1.0])\n",
        "\n",
        "ax1.set_title(r'$\\Omega_{\\rm m}$')\n",
        "ax2.set_title(r'$\\sigma_8$')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ8PA4GnA93D"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}